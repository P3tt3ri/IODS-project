# 5. Dimensionality reduction techniques 

Due to time pressures, this chapter is very sparse in terms of explanations. I just ran through the programming steps. Here goes, anyway:

## 5.1 The data

First I read the wrangled data from my project folder:
```{r}
human = read.csv2("~/GitHub/IODS-project/data/human.csv", stringsAsFactors = FALSE, row.names = 1)

```
### 5.1.1 Variables 

Health and knowledge:

"GNI" = Gross National Income per capita

"Life.Exp" = Life expectancy at birth

"Edu.Exp" = Expected years of schooling 

"Mat.Mor" = Maternal mortality ratio

"Ado.Birth" = Adolescent birth rate

Empowerment

"Parli.F" = Percetange of female representatives in parliament

"Edu2.F" = Proportion of females with at least secondary education

"Edu2.M" = Proportion of males with at least secondary education

"Labo.F" = Proportion of females in the labour force

"Labo.M" " Proportion of males in the labour force

"Edu2.FM" = Edu2.F / Edu2.M

"Labo.FM" = Labo2.F / Labo2.M

### 5.1.2 Summary of variables and a graphical overview:

```{r}
summary(human)
library(GGally)
ggpairs(human)
```

Some observations on the data:

* Most distributions have a strong skew. The only variable with a distribution that even vaguely approaches normal distribution is **Parli.F.**.  
* There's a moderate or strong correlation between some variables. They are pretty predictable: GNI correlates positively with life expectancy and expected years of education an so on.


## 5.2 Principal component analysis

### 5.2.1 Not-standardized version

We build a PCA model with unstandardized variables. Then we print the PCA coefficients and their summary.
```{r}
pca_human <- prcomp(human)
print(pca_human)
summary(pca_human)
```

Principal component 1 explains practically all variance. GNI's coefficient in PC1 is orders of magnitude greater than any other variable's. Then we draw a biplot.

```{r warning=FALSE}
# draw a biplot of the principal component representation and the original variables
s = summary(pca_human)
  pca_pr <- round(100*s$importance[2, ], digits = 1)

# create object pc_lab to be used as axis labels
pc_lab = paste0(names(pca_pr), " (", pca_pr, "%)")

# draw a biplot
biplot(pca_human, cex = c(0.2, 0.6), col = c("grey40", "deeppink2"), 
xlab = pc_lab[1], ylab = pc_lab[2])

```

Biplot is a kind of misnomer for this plot because PC1 explains very nearly all variance and because the numerical values of the nonstandardized GNI overshadow all other variables in terms of variance.

### 5.2.2 Standardized version
 
This time we standardize variables so they'll have a zero mean and unit variance. Then we repeat the steps of 5.2.1.

```{r}
human_std <- scale(human)

# print out summaries of the standardized variables
summary(human_std)

# perform principal component analysis (with the SVD method)
pca_human <- prcomp(human_std)
print(pca_human)
summary(pca_human)

```

This time the first two components explain only about 70 % of the variance. With standardized data GNI is just another variable. If we wanted to account for 90% of the variance, we'd need 5 principal components.

```{r}
# draw a biplot of the principal component representation and the original variables
s = summary(pca_human)
  pca_pr <- round(100*s$importance[2, ], digits = 1)

# create object pc_lab to be used as axis labels
pc_lab = paste0(names(pca_pr), " (", pca_pr, "%)")

# draw a biplot
biplot(pca_human, cex = c(0.2, 0.6), col = c("grey40", "deeppink2"), 
xlab = pc_lab[1], ylab = pc_lab[2])

```

Variables Edu2.FM and Parli.F correlate strongly with PC2, the rest with PC1. The first dimension (component) seems to be a measure of socio-economical factors and the second of women's participation in society.  

## 5.3 Multiple Correspondence Analysis

Unfortunately I have to leave this part undone. I can't spend more time on this week's assignment. So that's all, folks!
